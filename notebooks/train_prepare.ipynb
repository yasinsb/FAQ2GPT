{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "train_data_path = '../train_data'\n",
    "faq_data = []\n",
    "\n",
    "# Iterate through the JSON files in the train_data folder\n",
    "for filename in os.listdir(train_data_path):\n",
    "    if filename.endswith('.json'):\n",
    "        file_path = os.path.join(train_data_path, filename)\n",
    "        \n",
    "        # Read the JSON file\n",
    "        with open(file_path, 'r') as file:\n",
    "            data = json.load(file)\n",
    "            faq_data.append(data)\n",
    "\n",
    "# Process the faq_data as needed for training\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../train_data//training_data.jsonl', 'w') as file:\n",
    "    for section in faq_data:\n",
    "        for qa in section['prompts']:\n",
    "            question = qa['question']\n",
    "            answer = \" \" + qa['answer'] + \"\\n\"  # Add space at the beginning and newline at the end\n",
    "            \n",
    "            prompt_completion_pair = {\n",
    "                \"prompt\": question,\n",
    "                \"completion\": answer\n",
    "            }\n",
    "            \n",
    "            file.write(json.dumps(prompt_completion_pair) + '\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/yasinsalimibeni/Documents/github/FAQ2GPT/notebooks\n"
     ]
    }
   ],
   "source": [
    "! pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzing...\n",
      "\n",
      "- Your file contains 41 prompt-completion pairs. In general, we recommend having at least a few hundred examples. We've found that performance tends to linearly increase for every doubling of the number of examples\n",
      "- All prompts end with suffix `?`\n",
      "- All completions end with suffix `\\n`\n",
      "\n",
      "No remediations found.\n",
      "\n",
      "You can use your file for fine-tuning:\n",
      "> openai api fine_tunes.create -t \"../train_data/training_data.jsonl\"\n",
      "\n",
      "After you’ve fine-tuned a model, remember that your prompt has to end with the indicator string `?` for the model to start generating completions, rather than continuing with the prompt. Make sure to include `stop=[\"\\n\"]` so that the generated texts ends at the expected place.\n",
      "Once your model starts training, it'll approximately take 3.01 minutes to train a `curie` model, and less for `ada` and `babbage`. Queue will approximately take half an hour per job ahead of you.\n"
     ]
    }
   ],
   "source": [
    "! openai tools fine_tunes.prepare_data -f ../train_data/training_data.jsonl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ['OPENAI_API_KEY'] = open(\"../keys/openapi.key\").read().strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Upload progress: 100%|████████████████████| 13.8k/13.8k [00:00<00:00, 17.2Mit/s]\n",
      "Uploaded file from ../train_data/training_data.jsonl: file-hkfwr3LZvKhYbwK7FZKrNcyD\n",
      "Created fine-tune: ft-7RKNFdg3yApdedw9hFSM4ysw\n",
      "Streaming events until fine-tuning is complete...\n",
      "\n",
      "(Ctrl-C will interrupt the stream, but not cancel the fine-tune)\n",
      "[2023-08-19 18:59:01] Created fine-tune: ft-7RKNFdg3yApdedw9hFSM4ysw\n",
      "[2023-08-19 18:59:09] Fine-tune costs $0.01\n",
      "[2023-08-19 18:59:09] Fine-tune enqueued. Queue number: 0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ! openai api fine_tunes.create -t train_data/training_data.jsonl -m ada --suffix \"ITC\"\n",
    "! openai api fine_tunes.create -t ../train_data/training_data.jsonl -m babbage --suffix \"ITC-bag-\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "! openai api fine_tunes.list > 'model_list.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "openapi_key = open('../keys/openapi.key', 'r').read().strip()\n",
    "import openai\n",
    "\n",
    "openai.api_key = openapi_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# system_messages = {\n",
    "#   \"role\": \"system\",\n",
    "#   \"content\": \"You are the AI customer support bot for Intergalactic Travel Corporation (ITC), a leading provider of space travel and transportation services. Your role is to assist customers with accurate and detailed information about ITC's offerings, including Starship Cruises, Galactic Freight, and Wormhole Express. Respond to inquiries about services, bookings, safety protocols, travel insurance, payment methods, and more. Maintain a professional and informative tone, and ensure that all responses align with ITC's mission to provide exceptional interstellar experiences.\"\n",
    "# }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "response = openai.Completion.create(\n",
    "  model=\"ada:ft-personal:itc-bot-2023-08-19-01-56-16\",\n",
    "  prompt=\"What services does Starship Cruises offer?\",\n",
    "  max_tokens=500\n",
    ")\n",
    "\n",
    "answer = response.choices[0].text\n",
    "print(answer)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "response = openai.Completion.create(\n",
    "#   model=\"ada:ft-personal:itc-bot-2023-08-19-01-56-16\",\n",
    "  prompt=\"What services does Starship Cruises offer?\",\n",
    "  max_tokens=500\n",
    ")\n",
    "\n",
    "answer = response.choices[0].text\n",
    "print(answer)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "f2g-dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
